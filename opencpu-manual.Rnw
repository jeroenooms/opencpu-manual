%%This is a very basic article template.
%%There is just one section and two subsections.
\documentclass{scrartcl}

<<insert-fun, echo=FALSE>>=
insert_fun = function(name) {
  read_chunk(lines = capture.output(dump(name, '')), labels = paste(name, 'source', sep = '-'))
}
@

\usepackage[colorlinks, urlcolor=blue]{hyperref}
\usepackage[toc,page]{appendix}
\usepackage{fullpage}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{verbatim}

\title{The OpenCPU Server Manual}
\subtitle{Version 0.8-0}
\author{Jeroen Ooms}
\date{}

\begin{document}

\maketitle

\noindent The latest version of this document is available at \href{https://github.com/jeroenooms/opencpu-manual}{https://github.com/jeroenooms/opencpu-manual}. Typos, comments, suggestions about this manual go in the \href{https://github.com/jeroenooms/opencpu-manual/issues}{issues page} for the repo. 

\tableofcontents

\section{What is OpenCPU}

Internet access, public cloud computing, live and open data and scientific super computers are transforming the landscape of data analysis. Researchers increasingly collaborate by sharing data, code and results online. This is a powerful way to learn and teach statistical analysis and at the same time it improves transparency and accessibility of the underlying methods. Moreover, by centralizing computation we can address some scalability challenges and facilitate direct integration of analyses in systems and applications. We expect that providing reprodicuble materials and analysis tools, in addition to a written report or article, will soon become an integral part of the scientific publication proces. The OpenCPU framework is a first attempt at building the foundations to support such integrated, collaborative, reproducible analysis systems. \\

The OpenCPU framework is based on R, Latex and Pandoc. The server exposes an HTTP API to share and execute scripts, functions and reproducible documents. The system addresses many of the domain specific problems inherent to scientific computing, and abstracts away technicalities behind a well defined intuitive HTTP interface. This provides a foundation for scalable applications with embedded statistical analysis, vizualization and reporting.

\subsection{Seperating analysis from web development}

When using OpenCPU, R is only used for what it is good at: analysis and graphics. The design completely seperates the statistical computing from other parts of your system or application. OpenCPU has been designed to run on a remote server, interfaced only through the HTTP API. Clients need no knowledge of R or Latex; the OpenCPU API defines a mapping between HTTP requests and R function calls which results in a natural RPC-like protocol. Any software program that speaks HTTP can call R functions and scripts, without the need to understand, generate or parse R code.

\begin{verbatim}
  curl http://localhost/ocpu/library/stats/R/rnorm/json --data n=3
  [
    3.05644,
    0.38511,
    1.11983
  ]
\end{verbatim}

\noindent From there, it is completely up to the client on how to process or present the output. OpenCPU deliberately does not include, suggest or enforce the use of any specific web development language, GUI, etc. You are not restricted to a limited set of available widgets or panels that fits the R paradigm. OpenCPU manages incoming requests, security, resource allocation, data I/O and other computing technicalities. From there, it is completely up to the developer(s) and their imagination how to design their application. This is a major difference with frameworks that ship with built-in templates to generate parameratized out-of-the-box widgets from R code. Emphasis in the design of OpenCPU is on reliability and simplicity in order to develop scalable, production quality software. Because OpenCPU layers on HTTP, we can leverage existing technology (cache-control, https, load balancing, etc). Finally, the API definition makes it possible to gracefully extend, reimplement or replace parts of the system in the future.

\subsection{Using OpenCPU in a team}

OpenCPU decouples the roles of analyst and web developer. The analyst implements and documents R functions or scripts, just as he is used to. The web developers can use their favorite language, tools and web frameworks to interact call these functions over HTTP. OpenCPU provides a bridge between these two systems, without imposing additional constraints on either side. There is no need for the web developer to learn R, nor does the analyst have to worry about GUIs or web related technicalities. This seperation is supposed to keep applications well organized and easy to maintain, while making collaboration within a team of statisticians and developers easier than when the two parts are tightly intertwined.

\subsection{OpenCPU is really open}

The design of OpenCPU has been driven by the paradigms of open-source, contributed code and reproducibile research which are central to the domain of scientific computing. This is where the design of OpenCPU deviates from a web development frameworks in other languages. A client is allowed to call any script or function from any package, and all source code is readable as well. In unix analogy: any user has \texttt{r-x} access on all resources on the system. OpenCPU does not restrict users to some predefined set of functionality: instead, all users are explicitly allowed to store and execute custom code on the server. OpenCPU wants users to play, share, run, produce and reproduce results with each other.\\

For these reasons, OpenCPU takes a different approach to security. OpenCPU uses AppArmor: a security module in the Linux kernel, to enforce security policies on a by-process level. These security restrictions make it possible to allow for arbitrary code execution, while protecting against abuse or compromising the system. The policies are completely customisable, and section \ref{security} talks a bit more on security and AppArmor. However, even though the system is designed to be open, it is not mandatory to use it that way. It is perfectly fine to employ OpenCPU solely as a reliable computational back-end inside some larger system or application, similar to e.g. your database server. In such a design, users do not interact directly with the OpenCPU server, and can only use functionality exposed in your application layer.

\subsection{OpenCPU Apps}

OpenCPU defines a standard way to build and share "apps". An OpenCPU app is an R package which, in addition to the regular contents, ships with some web page(s). These pages interact with the R functions in this package through the OpenCPU API. By convention, these web pages (html/css/js/etc files) are included in the \texttt{/inst/www/} directory of the R source package. This way, OpenCPU apps provide a convenient way to package and ship standalone R web applications. \\

\noindent Because OpenCPU apps are simply R packages, they are developed, distributed and installed the same way as any other R package. Several example apps are available from the OpenCPU github organization at \href{https://github.com/opencpu}{https://github.com/opencpu}. For example to install the \href{https://github.com/opencpu/gitstats}{gitstats} app, we can use the \texttt{devtools} package:

<<eval=FALSE>>=
library(devtools)
install_github("gitstats", "opencpu")
@

\noindent The application can then be opened in a browser. For example, if the application was installed on an OpenCPU cloud server, it would be available at \href{http://localhost/ocpu/library/gitstats/www}{http://localhost/ocpu/library/gitstats/www}. \\

\noindent To make developing OpenCPU apps easier, a simple Javascript client library is available called \href{https://github.com/jeroenooms/opencpu.js}{opencpu.js}. This library depends on jQuery and  uses \texttt{\$.ajax} to provide javascript wrappers to the OpenCPU API. It is not mandatory to use this javascript library, but it provides a convenient basis for building OpenCPU apps.

\subsection{The OpenCPU single-user server}

Two versions of OpenCPU are available: a single-user server that runs inside an interactive R session, and a cloud server that builds on Apache and Nginx. The single-user server is intended for development and local use only. The latest version can easily be installed in R from the Github repository:

<<install-opencpu, eval=FALSE>>=
library(devtools)
install_github("opencpu", "jeroenooms")
@

\noindent When the opencpu package is loaded, the server is automatically started:
<<load-opencpu>>=
library(opencpu)
@

\noindent Because R is single-threaded, the single-user server does not support concurrent requests (but httpuv does a good job in queueing them). Also it does not enforce any security. The single-user server is great for developing apps, that can later be published on the OpenCPU cloud server. When using the single-user server, we can easily load the apps for local use:

<<eval=FALSE>>=
install_github("gitstats", "opencpu")
opencpu$browse("gitstats")
@

\noindent The \texttt{opencpu\$browse} function will automatically open the app in the default web browser.  


\section{Installing the OpenCPU cloud server}

The OpenCPU cloud server runs on Ubuntu 12.04 (precise) or higher. The OpenCPU system consists of a number of standard Ubuntu installation packages. These are:

\begin{itemize}
 \item \texttt{opencpu} -- Meta package which installs both \texttt{opencpu-server} and \texttt{opencpu-cache}.
 \item \texttt{opencpu-server} -- The main OpenCPU API server. Depends on \texttt{R} and \texttt{apache2}.
 \item \texttt{opencpu-cache} --  OpenCPU caching server. Depends on \texttt{nginx}.
 \item \texttt{opencpu-full} -- Installs \texttt{opencpu} plus many \texttt{texlive} and \texttt{pandoc} packages.
\end{itemize}

\subsection{Getting an Ubuntu server}

OpenCPU requires Ubuntu version 12.04 or higher. Any version of Ubuntu will do, e.g. Ubuntu Desktop, Ubuntu Server, Kubuntu, Edubuntu, etc. The preferred way of running OpenCPU is on a clean Ubuntu Server edition. A copy of the Ubuntu Server installation disc ISO can be obtained from the Ubuntu download pages: \\

\url{http://www.ubuntu.com/download/server} \\

\noindent To easiest way to run Ubuntu Server on Amazon EC2 is by using
one of the official AMI's as provided by the ubuntu team: \\

\url{http://cloud-images.ubuntu.com/raring/current/} \\

\noindent Another possibility is to install a OpenCPU on a virtual Ubuntu server
inside another OS. For example, the free VMware Player is available for Windows 
and Linux, and on OSX one can use parallels to run an Ubuntu server. This way
you can install Ubuntu and OpenCPU safely on top of an existing system. \\

\subsection{Basic OpenCPU installation}

Before installing OpenCPU, make sure the system is up to date:

\begin{verbatim}
  sudo apt-get update
  sudo apt-get upgrade
\end{verbatim}
To install OpenCPU, first add the OpenCPU repository to the system:

\begin{verbatim}
  sudo add-apt-repository ppa:opencpu/opencpu-0.8 -y
  sudo apt-get update
\end{verbatim}
We can now go ahead and install the server:

\begin{verbatim}
  sudo apt-get install opencpu
\end{verbatim}
Installation on a clean server might take a while because R and Latex both have many dependencies. After installation is done, we should be able to open a browser and point it to the \texttt{/ocpu} path at server address e.g: \href{http://my.server.com/ocpu}{http://my.server.com/ocpu}. If the welcome page shows up, the installation has succeeded. 

\subsection{Custom OpenCPU installation}

When installing the \texttt{opencpu} package as described above, both the OpenCPU API server (\texttt{opencpu-server}) as well as the OpenCPU cache server (\texttt{opencpu-cache}) are installed. However one can also install one one or the other. For example to install only the API server we could do:

\begin{verbatim}
  sudo apt-get install opencpu-server
\end{verbatim}
Alternatively, to install only the cache server:

\begin{verbatim}
  sudo apt-get install opencpu-cache
\end{verbatim}
Note that installing just \texttt{opencpu-cache} is only useful in combination with another server running \texttt{opencpu-server}. This is how you would set up a load-balancer. Some additional configuration if needed to make the cache server proxy to OpenCPU servers other than localhost. \\

Finally, to get install OpenCPU together with a lot of other potentially useful things:

\begin{verbatim}
  sudo apt-get install opencpu-full
\end{verbatim}
This package will install \texttt{opencpu-server}, \texttt{opencpu-cache}, \texttt{pandoc}, \texttt{texlive}, and much more. Note that this takes is at least several GB on a clean system.

\subsection{Uninstall OpenCPU}

To uninstall either of the OpenCPU packages:

\begin{verbatim}
  sudo apt-get purge opencpu-server
  sudo apt-get purge opencpu-cache
\end{verbatim}
Alternatively, to remove all of OpenCPU at once:

\begin{verbatim}
  sudo apt-get purge opencpu-*
\end{verbatim}
  
\noindent Removing the \texttt{opencpu-0-8} \emph{repository} from the system is done by deleting the file from the \texttt{/etc/apt/sources.list.d/} directory.  
  
\section{Managing the OpenCPU cloud server}

To control the OpenCPU server:
\begin{verbatim}
  sudo service opencpu start
  sudo service opencpu stop
  sudo service opencpu restart
\end{verbatim}
This will automatically enable/disable OpenCPU in Apache2 and restart the server. If the \texttt{opencpu-cache} package has been installed this server can be controlled seperately:
\begin{verbatim}
  sudo service opencpu-cache start
  sudo service opencpu-cache stop
  sudo service opencpu-cache restart
\end{verbatim}
This will flush the cache and restart nginx. \textbf{Note that the cache server automatically sets up \texttt{iptables} to preroute incoming web traffic (80/443) through nginx.} This is one of the reasons why it is recommended to run OpenCPU on its own server.

\subsection{Relevant log files}

When things are not working as expected, in most cases the problem is reported by Apache or Linux. If the OpenCPU server is not coming online at all, likely there are errors in the Apache2 error logs:

\begin{verbatim}
  /var/log/apache2/error.log
\end{verbatim}
If you are seeing permission denied errors, either in the OpenCPU API or in the Apache2 logs, this is most likely related to AppArmor security profile. Violations are logged to:

\begin{verbatim}
  /var/log/kern.log
\end{verbatim}
Section \ref{security} goes in more detail on configuring security in the cloud server. 

\subsection{Installing R Packages on the server}

In order for packages to be accessible through the \texttt{/ocpu/library} API, they need to be installed in the global library. Note that R needs to be started as root to install packages in the global library. To install a single source package:
\begin{verbatim}
  sudo R CMD INSTALL glmnet_1.9-5.tar.gz
\end{verbatim}
Alternatively we can start an interactive session and install packages straight from CRAN or Github:
\begin{verbatim}
  sudo R
\end{verbatim}
From here it is business as usual:
<<eval=FALSE>>=
install.packages("ggplot2")
install.packages("glmnet")

library(devtools)
install_github("dplyr", "hadley")
@
\noindent After restarting the OpenCPU service, the packages are accassible through the API:\\

\indent \url{http://my.server.com/ocpu/library/ggplot2} \\
\indent \url{http://my.server.com/ocpu/library/glmnet} \\
\indent \url{http://my.server.com/ocpu/library/dplyr} \\

\noindent Alternatively, some precompiled \texttt{r-cran-xxx} packages are available straight from the Ubuntu repositories:
\begin{verbatim}
    sudo apt-get install r-cran-xml
\end{verbatim}
However, note that these packages will only work if they were built using R version 3.0 or higher, which is \textbf{not the case} for the standard packages that ship with Ubuntu Raring 13.04 or lower. Appendix \ref{c2d4u} explains how to use third party repositories like \texttt{c2d4u} instead.

\subsection{Configuring the OpenCPU cloud server}

The OpenCPU configuration file is written in \texttt{JSON} and located at:

\begin{verbatim}
  /etc/opencpu/server.conf
\end{verbatim}
It has a hand full of server-wide settings and options to enable/disable or finetune certain parts of the system. To modify configurations, one can edit this file, or alternatively create a new file in the directory \texttt{server.conf.d}. Files in \texttt{/etc/opencpu/server.conf.d/} with a filename that ends in \texttt{".conf"} will automatically be loaded by opencpu-server. These settings will override settings in \texttt{/etc/opencpu/server.conf}. The server needs a restart for changed configurations to take effect:

\begin{verbatim}
  sudo service opencpu restart
\end{verbatim}
Please make sure that any configuration files are formatted using valid JSON at all times. Finally their is an additional, not required configuration file that is only used for github authentication information:
\begin{verbatim}
  /etc/opencpu/secret.conf
\end{verbatim}
This is readable by the OpenCPU system, but not by OpenCPU users. It has only two fields: \texttt{client\_id} and \texttt{client\_secret}. Setting a valid Github "application access token" will raise hourly github api limits from 100 to 5000 hits per hour. Currently this is only relevant for listing repositories from a user though the \texttt{/ocpu/gist} and \texttt{/ocpu/github} API.

\subsection{Customizing the security profile}
\label{security}

The OpenCPU cloud server uses \texttt{AppArmor} profiles and the \texttt{RAppArmor} package to enforce security policies. For an introduction on the topic see the \href{https://github.com/jeroenooms/RAppArmor#readme}{RAppArmor Github page} and \href{http://arxiv.org/abs/1303.4808}{this paper}. The profiles used by the OpenCPU cloud server are stored in:

\begin{verbatim}
  /etc/apparmor.d/opencpu.d/
\end{verbatim}
The default profiles included with OpenCPU are quite liberal while preventing most malicous behavior. However, if you plan to use OpenCPU in production, it is recommended to review these policies and revise them according to your needs. To keep your custom rules seperated from the general profiles, add them to the \texttt{/etc/apparmor.d/opencpu.d/custom} file. After modifying a security profile restart AppArmor and OpenCPU:

\begin{verbatim}
  sudo service apparmor restart
  sudo service opencpu restart
\end{verbatim}
One nice way to debug a security profile is by monitoring the \texttt{kern.log} file while using OpenCPU:

\begin{verbatim}
  sudo tail -f /var/log/kern.log | grep opencpu
\end{verbatim}
If any R package or process called from OpenCPU attempts to do something that is not allowed in the current security profile, a line containing \texttt{DENIED} is printed to \texttt{kern.log}.

\section{Testing the OpenCPU API}

A complete overview and demonstration of the OpenCPU api is available on the website: \href{http://www.opencpu.org}{www.opencpu.org}. Below a few basic examples to illustrate basic functionality and verify that things are working. Also note that OpenCPU ships with a little testing page that can be used to do http requests. The testing page can be found at \url{http://my.server.com/ocpu/test}. 

\subsection{Using Curl to test}


\noindent Basic \texttt{HTTP GET} requests can be performed either by simply opening a url in a web browser, or with a curl command:

\begin{verbatim}
  curl -L http://my.server.com/ocpu/library/
\end{verbatim}
The \texttt{-L} flag makes \texttt{curl} follow redirects which is often useful. In addition you can add the \texttt{-v} flag for more verbose output which includes headers:
\begin{verbatim}
  curl -L -v http://my.server.com/ocpu/library/
\end{verbatim}

\noindent To perform a \texttt{HTTP POST} in curl, either use the \texttt{-X POST} or \texttt{-d [args]} flag. For example:

\begin{verbatim}
  curl http://localhost/ocpu/library/utils/R/sessionInfo -X POST
  curl http://localhost/ocpu/library/stats/R/rnorm -d n=10\&mean=100
\end{verbatim}

\subsection{Reading package objects, manuals and files}

\noindent The following endpoints can be accessed using \texttt{HTTP GET}:\\

\indent \url{http://localhost/ocpu/test} \\
\indent \url{http://localhost/ocpu/library} \\
\indent \url{http://localhost/ocpu/library/stats/R} \\
\indent \url{http://localhost/ocpu/library/stats/R/rnorm} \\
\indent \url{http://localhost/ocpu/library/stats/man} \\
\indent \url{http://localhost/ocpu/library/stats/man/rnorm/text} \\
\indent \url{http://localhost/ocpu/library/stats/man/rnorm/html} \\
\indent \url{http://localhost/ocpu/library/stats/man/rnorm/pdf} \\
\indent \url{http://localhost/ocpu/library/datasets} \\
\indent \url{http://localhost/ocpu/library/datasets/R/cars} \\
\indent \url{http://localhost/ocpu/library/datasets/R/cars/json} \\
\indent \url{http://localhost/ocpu/library/datasets/R/cars/csv} \\
\indent \url{http://localhost/ocpu/library/datasets/R/cars/tab} \\
\indent \url{http://localhost/ocpu/library/datasets/R/cars/rda} \\

\noindent Appart from R objects and manuals, you can also just access static files from any package: \\

\indent \url{http://localhost/ocpu/library/knitr/examples/} \\
\indent \url{http://localhost/ocpu/library/knitr/examples/knitr-minimal.Rnw} \\
\indent \url{http://localhost/ocpu/library/knitr/doc/knitr-intro.R} \\
\indent \url{http://localhost/ocpu/library/brew/example1.brew} \\
\indent \url{http://localhost/ocpu/library/devtools/NEWS} \\
\indent \url{http://localhost/ocpu/library/devtools/DESCRIPTION} 


\subsection{Calling a function}

\noindent Performing a \texttt{HTTP POST} on a function results in a function call where the http request arguments are mapped to the function call. In OpenCPU, a successful \texttt{POST} requests usually returns a \texttt{HTTP 201} status, and the response body contains the locations of the output data:

\begin{verbatim}
  curl http://localhost/ocpu/library/stats/R/rnorm -d n=10\&mean=100
  <
  < /ocpu/tmp/x032a8fee/R/.val
  < /ocpu/tmp/x032a8fee/stdout
  < /ocpu/tmp/x032a8fee/source
  < /ocpu/tmp/x032a8fee/console
  < /ocpu/tmp/x032a8fee/info
\end{verbatim}
The output can then be retrieved using \texttt{HTTP GET}. In this case we would get: \\

\indent \url{http://localhost/ocpu/tmp/x032a8fee/R/.val} \\
\indent \url{http://localhost/ocpu/tmp/x032a8fee/R/.val/json} \\
\indent \url{http://localhost/ocpu/tmp/x032a8fee/R/.val/ascii} \\
\indent \url{http://localhost/ocpu/tmp/x032a8fee/R/.val/rda} \\
\indent \url{http://localhost/ocpu/tmp/x032a8fee/console} \\

\noindent There is one exception to this rule: in the common special case where we are only interested in the \texttt{JSON} representation of the object returned by the function, we add another \texttt{/json} after the function name in the url of the \texttt{HTTP POST} request:

\begin{verbatim}
  curl http://localhost/ocpu/library/stats/R/rnorm/json -d n=2
  [
    -1.2804,
  	-0.75013
  ]
\end{verbatim}
In this case, a successfull call will not return 200 (instead of 201), and the response body contains the output from the function in JSON; no need to do an additional \texttt{GET} request. However in most cases, the two-step procedure is preferred.\\

\noindent Finally It is also possible to specify \emph{input} arguments to a function call using JSON:

\begin{verbatim}
  curl http://localhost/ocpu/library/stats/R/rnorm \
  -H "Content-Type: application/json" -d '{"n":10, "mean": 10, "sd":10}'
\end{verbatim}


\subsection{Executing a script}

Besides calling a function, the \texttt{HTTP POST} method can also be used to execute a script. The script is executed according to it's file extention. Currently the following extensions are supported: \texttt{R} (Rscript), \texttt{Rnw}, \texttt{Rmd} (knitr), \texttt{brew} (brew), \texttt{tex} (latex), \texttt{md} (pandoc):

\begin{verbatim}
  curl -X POST http://localhost/ocpu/library/knitr/examples/knitr-minimal.Rnw
  curl -X POST http://localhost/ocpu/library/knitr/examples/knitr-minimal.Rmd
  curl -X POST http://localhost/ocpu/library/knitr/doc/knitr-intro.R
  curl -X POST http://localhost/ocpu/library/brew/example1.brew
\end{verbatim}

\noindent In contrast to a function, a script has no formal arguments. Instead, the \texttt{HTTP POST} arguments can be passed to the script interpreter. For example, when calling a \texttt{brew} script, we can pass a value for the \href{https://www.rforge.net/doc/packages/brew/brew.html}{output} argument in brew (e.g. to send the output stream to a specific file), and \texttt{Rmd}/\texttt{md} files have a \href{https://www.rforge.net/doc/packages/knitr/pandoc.html}{format} argument to specify the pandoc output format:

\begin{verbatim}
  curl http://localhost/ocpu/library/knitr/examples/knitr-minimal.Rmd -d format=docx
  curl http://localhost/ocpu/library/knitr/examples/knitr-minimal.Rmd -d format=odt
  curl http://localhost/ocpu/library/knitr/examples/knitr-minimal.Rmd -d format=html
  curl http://localhost/ocpu/library/brew/example1.brew -d output=out.txt
\end{verbatim}


\subsection{External package repositories}

\noindent If the OpenCPU cloud server has direct access to the internet, it also provides access packages and/or scripts from external repositories, such as CRAN or Github. This is convenient for development: package authors and users can test and use OpenCPU apps without the need for an administrator to install packages on the server. Note that the administrator can easily disable these features so they might not be available on every OpenCPU server.\\

When a client requests a package from an external repository which is not already installed on the server, OpenCPU will attempt to install the package on the fly. For this reason, the first request might take quite a while. Also the request will fail if the package installation fails (for example due to missing dependencies). But once the package has been successfully installed, it will behave just as any other package on the server. \\

For performance reasons, the current implementation updates packages from external no more than once per 24h. So changes that were recently pushed to Github might not immediately be refelected by the OpenCPU server.

\subsubsection*{CRAN}

The \texttt{/ocpu/cran/:package/} API interfaces to packages which are \emph{current} on \href{http://cran.r-project.org/}{CRAN}: \\

\indent \url{http://localhost/ocpu/cran/} \\
\indent \url{http://localhost/ocpu/cran/plyr} \\
\indent \url{http://localhost/ocpu/cran/plyr/R} \\
\indent \url{http://localhost/ocpu/cran/plyr/R/ldply} \\
\indent \url{http://localhost/ocpu/cran/plyr/man} \\
\indent \url{http://localhost/ocpu/cran/plyr/man/ldply} \\
\indent \url{http://localhost/ocpu/cran/plyr/man/ldply/html} \\
\indent \url{http://localhost/ocpu/cran/plyr/man/ldply/pdf} 

\subsubsection*{Github}

The \texttt{/ocpu/github/:user/:package/} API interfaces to \textbf{packages} which are the current \texttt{master} branch in a Github user repository: \\

\indent \url{http://localhost/ocpu/github/hadley/} \\
\indent \url{http://localhost/ocpu/github/hadley/plyr} \\
\indent \url{http://localhost/ocpu/github/hadley/plyr/R} \\
\indent \url{http://localhost/ocpu/github/hadley/plyr/R/ldply} \\
\indent \url{http://localhost/ocpu/github/hadley/plyr/man/ldply} 

\subsubsection*{Gist}

The \texttt{/ocpu/gist/:user/:gistid/} API interfaces to \textbf{files} (scripts, documents) in a repository from a certain Gist user. The \texttt{/ocpu/gist} API does \textbf{not support R packages}. Just files: \\

\indent \url{http://localhost/ocpu/gist/hadley/} \\
\indent \url{http://localhost/ocpu/gist/hadley/5721744} \\
\indent \url{http://localhost/ocpu/gist/hadley/5721744/html.r} \\

\noindent Execute a script or reproducible document straight from gist:

\begin{verbatim}
  curl -X POST http://localhost/ocpu/gist/hadley/5721744/html.r
\end{verbatim}


\subsection{Test the caching server}

An easy way to test if the caching server works is simply by calling the same function twice in a short time. If the cache server is working, the output will be identical (and the second request returns really fast):

\begin{verbatim}
  curl http://localhost/ocpu/library/stats/R/rnorm -d n=10
  curl http://localhost/ocpu/library/stats/R/rnorm -d n=10
\end{verbatim}
Try to disable the cache server and run the same experiment again:
\begin{verbatim}
  sudo service opencpu-cache stop
\end{verbatim}
You should now see different responses. Afterwards, re-enable the caching server:
\begin{verbatim}
  sudo service opencpu-cache start
\end{verbatim}
Another way to infer if the caching server is active is by looking at the \texttt{Server} response header:
\begin{verbatim}
  curl -v http://localhost/ocpu/library/
\end{verbatim}
If the cache server is online the header will be \texttt{Server:nginx/1.2.6 (Ubuntu)}. If the cache server is offline, it will be \texttt{Server:Apache/2.2.22 (Ubuntu)}.

\begin{appendices}

\section{Installing \texttt{r-cran} packages from \texttt{c2d4u}}
\label{c2d4u}

R packages can be installed on the same server in the usual ways, as was described earlier. However, this way the packages need to be compiled from source which requires more time and additional build dependencies. As an alternative, Dirk Eddelbuettel and Michael Rutter have "debianized" many of the R packages on CRAN and Bioconductor. Thereby, precompiled binaries of these R packages can be installed using \texttt{apt-get}. For Ubuntu, many of these packages are available from Micheal's Launchpad repository:

\begin{verbatim}
  sudo add-apt-repository ppa:marutter/rrutter -y
  sudo add-apt-repository ppa:marutter/c2d4u -y
  sudo apt-get update
\end{verbatim}
This adds the repository to the system and updates the latest package list. To see which packages are currently available:

\begin{verbatim}
  apt-cache search r-cran
  apt-cache search r-bioc
\end{verbatim}
And to install:

\begin{verbatim}
  sudo apt-get install r-cran-ggplot2
\end{verbatim}
This is great but there is one caveat: because the packages are precompiled, they will only work if they were build using R 3.0 or higher. Fortunately this is the case for almost all packages on \texttt{c2d4u}. However, it is wise to double check this in R after installing, by inspecting the \texttt{Built} column from the \texttt{installed.packages()} output:
<<eval=FALSE>>=
allpackages <- installed.packages()
which(allpackages[,"Built"] < 3.0)
@
\noindent If any packages show up which have been built with an older version of R, it is best to uninstall them because they won't work and will cause an error when loaded.


\section{Using OpenCPU with RStudio}

The OpenCPU single-user server has been tested to work on RStudio desktop on both Windows and Mac, as well as in RStudio server. If RStudio server is hosted behind a firewall, \texttt{httpuv} might not be accessible, but users can still use the \texttt{/custom/ocpu} path on the RStudio server port. For example \texttt{rstudio.server.com/custom/ocpu}.\\

The OpenCPU cloud server works great together with RStudio server. Both systems run best on Ubuntu and will happily share the same R installation. You can use RStudio server to install R packages (and OpenCPU apps) to make them available through the OpenCPU API.

\end{appendices}

\end{document}